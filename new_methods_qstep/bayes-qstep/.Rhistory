# Load Packages
library(coda)
library(mvtnorm)
# Load Data
setwd("C:/Users/gk249/Downloads/Bayesian workshop/Data and codes")
# Load Data
#setwd("C:/Users/gk249/Downloads/Bayesian workshop/Data and codes")
birthwt<-read.csv("birthwt.csv")
# Load Data
#setwd("C:/Users/gk249/Downloads/Bayesian workshop/Data and codes")
birthwt<-read.csv(../"birthwt.csv")
library(here)
birthwt<-read.csv("birthwt.csv")
birthwt<-read.csv(here("bayes_workshop","birthwt.csv")
)
# Load Data
birthwt<-read.csv(here("bayes_workshop","birthwt.csv")
# Load Data
birthwt<-read.csv(here("bayes_workshop","birthwt.csv"))
# Set up data
X<-cbind(1, birthwt$smoke)
y<- birthwt$low
n<-nrow(X)
k<-ncol(X)
birthwt(1:3,)
# Load Data
birthwt<-read.csv(here("bayes_workshop","birthwt.csv"))
birthwt(1:3,)
birthwt[1:3,]
# Set up data
X<-cbind(1, birthwt$smoke)
X
birthwt[1:3,]
#### Priors
mbeta0<-rep(0,k)				# Prior Mean for Beta
vbeta0<-diag(10,k)			# Prior Cov of Beta (vague)
vbeta0<-diag(10,k)			# Prior Cov of Beta (vague)
vbeta0
#############
# MCMC Info #
#############
nsim<-5000  # MCMC Iterations
?solve
#############
# MCMC Info #
#############
nsim<-5000  # MCMC Iterations
thin<-5         	# Thinning Interval
burn<-nsim/2   		 # Burn-in #... how many to drop for 'inference'... give it time to reach the stationary state, to use when we consider the properties of the estimates
lastit<-(nsim-burn)/thin	# Last stored value
nchains<-3 # 3 completely independent processes
###################
# Store MCMC draws #
####################
Beta<-array(0,c(lastit,k,nchains))
colnames(Beta)<-c("Intercept", "Smoke")
###################
# Store MCMC draws #
####################
Beta<-array(0,c(lastit,k,nchains))
colnames(Beta)<-c("Intercept", "Smoke")
iBeta
Beta
for (l in 1:nchains) {
#Initial Values
beta<-matrix(0,k)
z<-rep(0,n)				# Latent Normal Variable
for (i in 1:nsim) {
muz<-X%*%beta
z[y==0]<-qnorm(runif(n,0,pnorm(0,muz,1)),muz,1)[y==0]
z[y==1]<-qnorm(runif(n,pnorm(0,muz,1),1),muz,1)[y==1]
mbeta <- vbeta%*%(prec0%*%mbeta0+crossprod(X,z))
beta<-matrix(rmvnorm(1,mbeta,vbeta))
if (i> burn & i%%thin==0) {
j<-(i-burn)/thin
Beta[j,,l]<-c(t(beta))
}
if (i%%1000==0) print(c(paste("chain=",l,sep=" "),paste("iteration=",i,sep="")))
}
}
?matrix
?%*%
for (i in 1:nsim) { #at each iteration
muz<-X%*%beta		#the 'y*' in the probit (latent)... random beta
z[y==0]<-qnorm(runif(n,0,pnorm(0,muz,1)),muz,1)[y==0] #
z[y==1]<-qnorm(runif(n,pnorm(0,muz,1),1),muz,1)[y==1]
mbeta <- vbeta%*%(prec0%*%mbeta0+crossprod(X,z)) #computing the posterior
beta<-matrix(rmvnorm(1,mbeta,vbeta)) #draws a random multivariate normal vector, with posterior mean and variance
if (i> burn & i%%thin==0) { #here is the part where we drop and keep stuff
j<-(i-burn)/thin
Beta[j,,l]<-c(t(beta))
}
if (i%%1000==0) print(c(paste("chain=",l,sep=" "),paste("iteration=",i,sep="")))
}
vbeta0<-diag(10,k)			# Prior Cov of Beta (vague) (note, in a real application we would use a much larger value)
prec0<-solve(vbeta0)			#
vbeta<-solve(prec0+crossprod(X,X))	# Posterior variance of beta
#############
# MCMC Info #
#############
nsim<-5000  # MCMC Iterations
thin<-5         	# Thinning Interval; don't save every iteration for inference save every 5th one; because close-ly spaced values may be correlated
burn<-nsim/2   		 # Burn-in #... how many to drop for 'inference'... give it time to reach the stationary state, to use when we consider the properties of the estimates in summarising the posterior and evaluating the model
lastit<-(nsim-burn)/thin	# Last stored value; number of draws I am saving for inference
nchains<-3 # 3 completely independent processes
###################
# Store MCMC draws #
####################
Beta<-array(0,c(lastit,k,nchains))
colnames(Beta)<-c("Intercept", "Smoke")
for (l in 1:nchains) {
#Initial Values
beta<-matrix(0,k)
z<-rep(0,n)				# Latent Normal Variable
for (i in 1:nsim) { #at each iteration
muz<-X%*%beta		#the 'y*' in the probit (latent)... random beta
z[y==0]<-qnorm(runif(n,0,pnorm(0,muz,1)),muz,1)[y==0] #
z[y==1]<-qnorm(runif(n,pnorm(0,muz,1),1),muz,1)[y==1]
mbeta <- vbeta%*%(prec0%*%mbeta0+crossprod(X,z)) #computing the posterior
beta<-matrix(rmvnorm(1,mbeta,vbeta)) #draws a random multivariate normal vector, with posterior mean and variance
if (i> burn & i%%thin==0) { #here is the part where we drop and keep stuff
j<-(i-burn)/thin
Beta[j,,l]<-c(t(beta))
}
if (i%%1000==0) print(c(paste("chain=",l,sep=" "),paste("iteration=",i,sep="")))
}
}
dim(Beta)
beta
vbeta0
vbeta
# Check Convergence
gelman.diag(mcmc.list(as.mcmc(Beta[,,1]), as.mcmc(Beta[,,2]), as.mcmc(Beta[,,3])))
# Posterior Summaries
cbind(colMeans(BETA), HPDinterval(as.mcmc(BETA), p=0.95))
BETA<-rbind(Beta[,,1],Beta[,,2],Beta[,,3])
# Posterior Summaries
cbind(colMeans(BETA), HPDinterval(as.mcmc(BETA), p=0.95))
# Check Convergence
gelman.diag(mcmc.list(as.mcmc(Beta[,,1]), as.mcmc(Beta[,,2]), as.mcmc(Beta[,,3])))
setwd("C:/Users/gk249/Downloads/Bayesian workshop/Data and codes")
library(rjags)
install.packages("rjags")
?pacman
install.packages("MCMCpack")
library(MCMCpack)
data(birthwt)
probit.data<-list(
"n"=nrow(birthwt),
"y"=birthwt$low,
"x"=birthwt$smoke)
probit.parameters<-c(
"beta"
)
set.seed(1982)
probit.inits<-function() {
list(
beta=rnorm(2)
)
}
jags.probit <- jags.model( file = "probit.bug",
data=probit.data, inits=probit.inits, n.chains=1, n.adapt=500 )
jags.probit <- jags.model( file = "probit.bug",
data=probit.data, inits=probit.inits, n.chains=1, n.adapt=500 )
jags.probit <- jags.model( file = "probit.bug",
data=probit.data, inits=probit.inits, n.chains=1, n.adapt=500 )
probit <- coda.samples( jags.probit, probit.parameters, n.iter=10000 )
data(birthwt)
probit.data<-list(
"n"=nrow(birthwt),
"y"=birthwt$low,
"x"=birthwt$smoke)
probit.parameters<-c(
"beta"
)
data(birthwt)
?data
?dbern
dbern
dbern()
jags.probit <- jags.model( file = "probit.bug",
data=probit.data, inits=probit.inits, n.chains=1, n.adapt=500 ) #the model file, here 'probit.bug' needs to be specified
#setwd("C:/Users/gk249/Downloads/Bayesian workshop/Data and codes")
install.packages("rjags")
library(rjags)
jags.probit <- jags.model( file = "probit.bug",
data=probit.data, inits=probit.inits, n.chains=1, n.adapt=500 ) #the model file, here 'probit.bug' needs to be specified
here()
jags.probit <- jags.model( file = here("bayes-workshop","JAGS","probit.bug"),
data=probit.data, inits=probit.inits, n.chains=1, n.adapt=500 ) #the model file, here 'probit.bug' needs to be specified
here()
jags.probit <- jags.model( file = here("bayes_workshop","JAGS","probit.bug"),
data=probit.data, inits=probit.inits, n.chains=1, n.adapt=500 ) #the model file, here 'probit.bug' needs to be specified
summary(probit)
probit <- coda.samples( jags.probit, probit.parameters, n.iter=10000 )
summary(probit)
jags.probit <- jags.model( file = here("bayes_workshop","JAGS","probit.bug"),
data=probit.data, inits=probit.inits, n.chains=1, n.adapt=500 ) #the model file, here 'probit.bug' needs to be specified  #first 500 are burned
probit <- coda.samples( jags.probit, probit.parameters, n.iter=10000 )
summary(probit)
?coda.samples
desc(probit)
str(probit)
mcmc()
probit
setwd("C:/Users/gk249/Downloads/Bayesian workshop/Data and codes")
library(R2WinBUGS)
rm(list=ls())
### Suppose now that some covariates are missing as well
n<-2000
x<-rbinom(n, 1, 0.7)
X<-cbind(1,x)
beta<-c(0.7, 1.2)
y<-X%*%beta+rnorm(n)
y[sample(1:n,500)]<-NA
x[sample(1:n, 200)]<-NA
y
y
sum(is.na(y))
y.missing<-which(is.na(y))
y.missing
x
sum(is.na(x))
x.missing<-which(is.na(x))
x.missing
regression.data<-list(
"n"=n,
"y"=as.vector(y),
"x"=x)
regression.parameters<-c(
"beta", "sigma2", "y", "x"
)
set.seed(1982)
regression.inits<-function() {
list(
beta=rnorm(2), precision=runif(1,0,1), alpha=rnorm(1)
)
}
regression<-bugs(regression.data,regression.inits,regression.parameters,
"regression.covariatemissing.bug",
n.chains=3, n.iter=500, debug=TRUE,
#n.chains=3, n.iter=150000, n.burnin=5000,
#bugs.directory="C:/WinBUGS14")
bugs.directory="//isad.isadroot.ex.ac.uk/UOE/User/Desktop/WinBUGS14")
attach(regression)
print(regression)
