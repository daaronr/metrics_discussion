<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>8 Notes on Bayesian approaches – David Reinstein | Econometrics, statistics, and data science: Reinstein notes with a Micro, Behaviural, and Experimental focus</title>
  <meta name="description" content="8 Notes on Bayesian approaches – David Reinstein | Econometrics, statistics, and data science: Reinstein notes with a Micro, Behaviural, and Experimental focus" />
  <meta name="generator" content="bookdown 0.17 and GitBook 2.6.7" />

  <meta property="og:title" content="8 Notes on Bayesian approaches – David Reinstein | Econometrics, statistics, and data science: Reinstein notes with a Micro, Behaviural, and Experimental focus" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="daaronr/metrics_discussion_work" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="8 Notes on Bayesian approaches – David Reinstein | Econometrics, statistics, and data science: Reinstein notes with a Micro, Behaviural, and Experimental focus" />
  
  
  

<meta name="author" content="Dr. David Reinstein," />


<meta name="date" content="2020-04-25" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="causal-pathways-selection-corners-hurdles-and-conditional-on-estimates-1.html"/>

<style type="text/css">
p.abstract{
  text-align: center;
  font-weight: bold;
}
div.abstract{
  margin: auto;
  width: 90%;
}
</style>
<script src="libs/header-attrs-2.1/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<!-- font families -->

<link href="https://fonts.googleapis.com/css?family=PT+Sans|Pacifico|Source+Sans+Pro" rel="stylesheet">

<!-- <script src="js/hideOutput.js"></script> -->

<!-- Mathjax -->
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/default.js"></script>

 <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        extensions: ["tex2jax.js", "TeX/AMSmath.js"],
        tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
        jax: ["input/TeX","output/CommonHTML"]
      });
      MathJax.Hub.processSectionDelay = 0;
  </script>



<!-- open review block, in case we want it ever

<script async defer src="https://hypothes.is/embed.js"></script>
-->

<!-- Folding text box javascript thing -->

<script type="text/javascript">
$(document).ready(function() {
  $folds = $(".fold");
  $folds.wrapInner("<div class=\"fold-blck\">"); // wrap a div container around content
  $folds.prepend("<button class=\"fold-btn\">Unfold</button>");  // add a button
  $(".fold-blck").toggle();  // fold all blocks
  $(".fold-btn").on("click", function() {  // add onClick event
    $(this).text($(this).text() === "Fold" ? "Unfold" : "Fold");  // if the text equals "Fold", change it to "Unfold"or else to "Fold"
    $(this).next(".fold-blck").toggle("linear");  // "swing" is the default easing function. This can be further customized in its speed or the overall animation itself.
  })
});
</script>


<script type="text/javascript">

// toggle visibility of R source blocks in R Markdown output
function toggle_R() {
  var x = document.getElementsByClassName('r');
  if (x.length == 0) return;
  function toggle_vis(o) {
    var d = o.style.display;
    o.style.display = (d == 'block' || d == '') ? 'none':'block';
  }

  for (i = 0; i < x.length; i++) {
    var y = x[i];
    if (y.tagName.toLowerCase() === 'pre') toggle_vis(y);
  }

    var elem = document.getElementById("myButton1");
    if (elem.value === "Hide Global") elem.value = "Show Global";
    else elem.value = "Hide Global";
}

document.write('<input onclick="toggle_R();" type="button" value="Hide Global" id="myButton1" style="position: absolute; top: 10%; right: 2%; z-index: 200"></input>')

</script>

<!-- Global site tag (gtag.js) - Google Analytics
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-148137970-3"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-148137970-3');
</script>
-->


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  background-color: #f8f8f8; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#conceptual"><i class="fa fa-check"></i><b>1.1</b> Conceptual</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="introduction.html"><a href="introduction.html#bayesian-vs.-frequentist-approaches"><i class="fa fa-check"></i><b>1.1.1</b> Bayesian vs. frequentist approaches</a></li>
<li class="chapter" data-level="1.1.2" data-path="introduction.html"><a href="introduction.html#causal-vs.-descriptive-treatment-effects-and-the-potential-outcomes-causal-model"><i class="fa fa-check"></i><b>1.1.2</b> Causal vs. descriptive; ‘treatment effects’ and the potential outcomes causal model</a></li>
<li class="chapter" data-level="1.1.3" data-path="introduction.html"><a href="introduction.html#theory-restrictions-and-structural-vs-reduced-form"><i class="fa fa-check"></i><b>1.1.3</b> Theory, restrictions, and ‘structural vs reduced form’</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="introduction.html"><a href="introduction.html#getting-cleaning-and-using-data"><i class="fa fa-check"></i><b>1.2</b> Getting, cleaning and using data</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="introduction.html"><a href="introduction.html#data-whatwhywherehow"><i class="fa fa-check"></i><b>1.2.1</b> Data: What/why/where/how</a></li>
<li class="chapter" data-level="1.2.2" data-path="introduction.html"><a href="introduction.html#good-coding-practices"><i class="fa fa-check"></i><b>1.2.2</b> Good coding practices</a></li>
<li class="chapter" data-level="1.2.3" data-path="introduction.html"><a href="introduction.html#new-tools-and-approaches-to-data-esp-tidyverse"><i class="fa fa-check"></i><b>1.2.3</b> New tools and approaches to data (esp ‘tidyverse’)</a></li>
<li class="chapter" data-level="1.2.4" data-path="introduction.html"><a href="introduction.html#data-sharing-and-integrity"><i class="fa fa-check"></i><b>1.2.4</b> Data sharing and integrity</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="introduction.html"><a href="introduction.html#basic-regression-and-statistical-inference-common-mistakes-and-issues"><i class="fa fa-check"></i><b>1.3</b> Basic regression and statistical inference: Common mistakes and issues</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="introduction.html"><a href="introduction.html#bad-control-colliders"><i class="fa fa-check"></i><b>1.3.1</b> “Bad control” (“colliders”)</a></li>
<li class="chapter" data-level="1.3.2" data-path="introduction.html"><a href="introduction.html#choices-of-lhs-and-rhs-variables"><i class="fa fa-check"></i><b>1.3.2</b> Choices of lhs and rhs variables</a></li>
<li class="chapter" data-level="1.3.3" data-path="introduction.html"><a href="introduction.html#functional-form"><i class="fa fa-check"></i><b>1.3.3</b> Functional form</a></li>
<li class="chapter" data-level="1.3.4" data-path="introduction.html"><a href="introduction.html#ols-and-heterogeneity"><i class="fa fa-check"></i><b>1.3.4</b> OLS and heterogeneity</a></li>
<li class="chapter" data-level="1.3.5" data-path="introduction.html"><a href="introduction.html#null-effects"><i class="fa fa-check"></i><b>1.3.5</b> “Null effects”</a></li>
<li class="chapter" data-level="1.3.6" data-path="introduction.html"><a href="introduction.html#multiple-hypothesis-testing-mht"><i class="fa fa-check"></i><b>1.3.6</b> Multiple hypothesis testing (MHT)</a></li>
<li class="chapter" data-level="1.3.7" data-path="introduction.html"><a href="introduction.html#interaction-terms-and-pitfalls"><i class="fa fa-check"></i><b>1.3.7</b> Interaction terms and pitfalls</a></li>
<li class="chapter" data-level="1.3.8" data-path="introduction.html"><a href="introduction.html#choice-of-test-statistics-including-nonparametric"><i class="fa fa-check"></i><b>1.3.8</b> Choice of test statistics (including nonparametric)</a></li>
<li class="chapter" data-level="1.3.9" data-path="introduction.html"><a href="introduction.html#how-to-display-and-write-about-regression-results-and-tests"><i class="fa fa-check"></i><b>1.3.9</b> How to display and write about regression results and tests</a></li>
<li class="chapter" data-level="1.3.10" data-path="introduction.html"><a href="introduction.html#bayesian-interpretations-of-results"><i class="fa fa-check"></i><b>1.3.10</b> Bayesian interpretations of results</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="introduction.html"><a href="introduction.html#ldv-and-discrete-choice-modeling"><i class="fa fa-check"></i><b>1.4</b> LDV and discrete choice modeling</a></li>
<li class="chapter" data-level="1.5" data-path="introduction.html"><a href="introduction.html#robustness-and-diagnostics-with-integrity"><i class="fa fa-check"></i><b>1.5</b> Robustness and diagnostics, with integrity</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="introduction.html"><a href="introduction.html#how-can-diagnostic-tests-make-sense-where-is-the-burden-of-proof"><i class="fa fa-check"></i><b>1.5.1</b> (How) can diagnostic tests make sense? Where is the burden of proof?</a></li>
<li class="chapter" data-level="1.5.2" data-path="introduction.html"><a href="introduction.html#estimating-standard-errors"><i class="fa fa-check"></i><b>1.5.2</b> Estimating standard errors</a></li>
<li class="chapter" data-level="1.5.3" data-path="introduction.html"><a href="introduction.html#sensitivity-analysis-interactive-presentation"><i class="fa fa-check"></i><b>1.5.3</b> Sensitivity analysis: Interactive presentation</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="introduction.html"><a href="introduction.html#control-strategies-and-prediction-machine-learning-approaches"><i class="fa fa-check"></i><b>1.6</b> <span>Control strategies and prediction; Machine Learning approaches</span></a>
<ul>
<li class="chapter" data-level="1.6.1" data-path="introduction.html"><a href="introduction.html#machine-learning-statistical-learning-lasso-ridge-and-more"><i class="fa fa-check"></i><b>1.6.1</b> Machine Learning (statistical learning): Lasso, Ridge, and more</a></li>
<li class="chapter" data-level="1.6.2" data-path="introduction.html"><a href="introduction.html#limitations-to-inference-from-learning-approaches"><i class="fa fa-check"></i><b>1.6.2</b> Limitations to inference from learning approaches</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="introduction.html"><a href="introduction.html#iv-and-its-many-issues"><i class="fa fa-check"></i><b>1.7</b> IV and its many issues</a>
<ul>
<li class="chapter" data-level="1.7.1" data-path="introduction.html"><a href="introduction.html#instrument-validity"><i class="fa fa-check"></i><b>1.7.1</b> Instrument validity</a></li>
<li class="chapter" data-level="1.7.2" data-path="introduction.html"><a href="introduction.html#heterogeneity-and-late"><i class="fa fa-check"></i><b>1.7.2</b> Heterogeneity and LATE</a></li>
<li class="chapter" data-level="1.7.3" data-path="introduction.html"><a href="introduction.html#weak-instruments-other-issues"><i class="fa fa-check"></i><b>1.7.3</b> Weak instruments, other issues</a></li>
<li class="chapter" data-level="1.7.4" data-path="introduction.html"><a href="introduction.html#reference-to-the-use-of-iv-in-experimentsmediation"><i class="fa fa-check"></i><b>1.7.4</b> Reference to the use of IV in experiments/mediation</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="introduction.html"><a href="introduction.html#causal-pathways-mediation-modeling-and-its-massive-limitations"><i class="fa fa-check"></i><b>1.8</b> Causal pathways: <span>Mediation modeling and its massive limitations</span></a></li>
<li class="chapter" data-level="1.9" data-path="introduction.html"><a href="introduction.html#causal-pathways-selection-corners-hurdles-and-conditional-on-estimates"><i class="fa fa-check"></i><b>1.9</b> Causal pathways: selection, corners, hurdles, and ‘conditional on’ estimates</a>
<ul>
<li class="chapter" data-level="1.9.1" data-path="introduction.html"><a href="introduction.html#corner-solution-or-hurdle-variables-and-conditional-on-positive"><i class="fa fa-check"></i><b>1.9.1</b> ‘Corner solution’ or hurdle variables and ‘Conditional on Positive’</a></li>
</ul></li>
<li class="chapter" data-level="1.10" data-path="introduction.html"><a href="introduction.html#other-paths-to-observational-identification"><i class="fa fa-check"></i><b>1.10</b> Other paths to observational identification</a>
<ul>
<li class="chapter" data-level="1.10.1" data-path="introduction.html"><a href="introduction.html#fixed-effects-and-differencing"><i class="fa fa-check"></i><b>1.10.1</b> Fixed effects and differencing</a></li>
<li class="chapter" data-level="1.10.2" data-path="introduction.html"><a href="introduction.html#did"><i class="fa fa-check"></i><b>1.10.2</b> DiD</a></li>
<li class="chapter" data-level="1.10.3" data-path="introduction.html"><a href="introduction.html#rd"><i class="fa fa-check"></i><b>1.10.3</b> RD</a></li>
<li class="chapter" data-level="1.10.4" data-path="introduction.html"><a href="introduction.html#time-series-ish-panel-approaches-to-micro"><i class="fa fa-check"></i><b>1.10.4</b> Time-series-ish panel approaches to micro</a></li>
</ul></li>
<li class="chapter" data-level="1.11" data-path="introduction.html"><a href="introduction.html#ex-ante-power-calculations"><i class="fa fa-check"></i><b>1.11</b> (Ex-ante) Power calculations</a>
<ul>
<li class="chapter" data-level="1.11.1" data-path="introduction.html"><a href="introduction.html#what-sort-of-power-calculations-make-sense-and-what-is-the-point"><i class="fa fa-check"></i><b>1.11.1</b> What sort of ‘power calculations’ make sense, and what is the point?</a></li>
<li class="chapter" data-level="1.11.2" data-path="introduction.html"><a href="introduction.html#power-calculations-without-real-data"><i class="fa fa-check"></i><b>1.11.2</b> Power calculations without real data</a></li>
<li class="chapter" data-level="1.11.3" data-path="introduction.html"><a href="introduction.html#power-calculations-using-prior-data"><i class="fa fa-check"></i><b>1.11.3</b> Power calculations using prior data</a></li>
</ul></li>
<li class="chapter" data-level="1.12" data-path="introduction.html"><a href="introduction.html#experimental-study-design-identifying-meaningful-and-useful-causal-relationships-and-parameters"><i class="fa fa-check"></i><b>1.12</b> (Experimental) Study design: Identifying meaningful and useful (causal) relationships and parameters</a>
<ul>
<li class="chapter" data-level="1.12.1" data-path="introduction.html"><a href="introduction.html#why-run-an-experiment-or-study"><i class="fa fa-check"></i><b>1.12.1</b> Why run an experiment or study?</a></li>
<li class="chapter" data-level="1.12.2" data-path="introduction.html"><a href="introduction.html#causal-channels-and-identification"><i class="fa fa-check"></i><b>1.12.2</b> Causal channels and identification</a></li>
<li class="chapter" data-level="1.12.3" data-path="introduction.html"><a href="introduction.html#types-of-experiments-demand-effects-and-more-artifacts-of-artifical-setups"><i class="fa fa-check"></i><b>1.12.3</b> Types of experiments, ‘demand effects’ and more artifacts of artifical setups</a></li>
<li class="chapter" data-level="1.12.4" data-path="introduction.html"><a href="introduction.html#generalizability-and-heterogeneity"><i class="fa fa-check"></i><b>1.12.4</b> Generalizability (and heterogeneity)</a></li>
</ul></li>
<li class="chapter" data-level="1.13" data-path="introduction.html"><a href="introduction.html#experimental-study-design-background-and-quantitative-issues"><i class="fa fa-check"></i><b>1.13</b> (Experimental) Study design: Background and quantitative issues</a>
<ul>
<li class="chapter" data-level="1.13.1" data-path="introduction.html"><a href="introduction.html#pre-registration-and-pre-analysis-plans"><i class="fa fa-check"></i><b>1.13.1</b> Pre-registration and Pre-analysis plans</a></li>
<li class="chapter" data-level="1.13.2" data-path="introduction.html"><a href="introduction.html#sequential-and-adaptive-designs"><i class="fa fa-check"></i><b>1.13.2</b> Sequential and adaptive designs</a></li>
<li class="chapter" data-level="1.13.3" data-path="introduction.html"><a href="introduction.html#efficient-assignment-of-treatments"><i class="fa fa-check"></i><b>1.13.3</b> Efficient assignment of treatments</a></li>
</ul></li>
<li class="chapter" data-level="1.14" data-path="introduction.html"><a href="introduction.html#experimetrics-and-measurement-of-treatment-effects-from-rcts"><i class="fa fa-check"></i><b>1.14</b> ‘Experimetrics’ and measurement of treatment effects from RCTs</a>
<ul>
<li class="chapter" data-level="1.14.1" data-path="introduction.html"><a href="introduction.html#which-error-structure-random-effects"><i class="fa fa-check"></i><b>1.14.1</b> Which error structure? Random effects?</a></li>
<li class="chapter" data-level="1.14.2" data-path="introduction.html"><a href="introduction.html#randomization-inference"><i class="fa fa-check"></i><b>1.14.2</b> Randomization inference?</a></li>
<li class="chapter" data-level="1.14.3" data-path="introduction.html"><a href="introduction.html#parametric-and-nonparametric-tests-of-simple-hypotheses"><i class="fa fa-check"></i><b>1.14.3</b> Parametric and nonparametric tests of simple hypotheses</a></li>
<li class="chapter" data-level="1.14.4" data-path="introduction.html"><a href="introduction.html#adjustments-for-exogenous-but-non-random-treatment-assignment"><i class="fa fa-check"></i><b>1.14.4</b> Adjustments for exogenous (but non-random) treatment assignment</a></li>
<li class="chapter" data-level="1.14.5" data-path="introduction.html"><a href="introduction.html#iv-in-an-experimental-context-to-get-at-mediators"><i class="fa fa-check"></i><b>1.14.5</b> IV in an experimental context to get at ‘mediators’?</a></li>
<li class="chapter" data-level="1.14.6" data-path="introduction.html"><a href="introduction.html#heterogeneity-in-an-experimental-context"><i class="fa fa-check"></i><b>1.14.6</b> Heterogeneity in an experimental context</a></li>
</ul></li>
<li class="chapter" data-level="1.15" data-path="introduction.html"><a href="introduction.html#the-bayesian-approach"><i class="fa fa-check"></i><b>1.15</b> The Bayesian approach</a></li>
<li class="chapter" data-level="1.16" data-path="introduction.html"><a href="introduction.html#making-inferences-from-previous-work-meta-analysis-combining-studies"><i class="fa fa-check"></i><b>1.16</b> Making inferences from previous work; Meta-analysis, combining studies</a>
<ul>
<li class="chapter" data-level="1.16.1" data-path="introduction.html"><a href="introduction.html#publication-bias"><i class="fa fa-check"></i><b>1.16.1</b> Publication bias</a></li>
<li class="chapter" data-level="1.16.2" data-path="introduction.html"><a href="introduction.html#combining-a-few-your-own-studiesestimates"><i class="fa fa-check"></i><b>1.16.2</b> Combining a few (your own) studies/estimates</a></li>
<li class="chapter" data-level="1.16.3" data-path="introduction.html"><a href="introduction.html#full-meta-analyses"><i class="fa fa-check"></i><b>1.16.3</b> Full meta-analyses</a></li>
</ul></li>
<li class="chapter" data-level="1.17" data-path="introduction.html"><a href="introduction.html#some-key-resources-and-references"><i class="fa fa-check"></i><b>1.17</b> Some key resources and references</a>
<ul>
<li class="chapter" data-level="1.17.1" data-path="introduction.html"><a href="introduction.html#consider"><i class="fa fa-check"></i><b>1.17.1</b> Consider:</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="reg-follies.html"><a href="reg-follies.html"><i class="fa fa-check"></i><b>2</b> Basic regression and statistical inference: Common mistakes and issues</a>
<ul>
<li class="chapter" data-level="2.1" data-path="reg-follies.html"><a href="reg-follies.html#basic-regression-and-statistical-inference-common-mistakes-and-issues-briefly-listed"><i class="fa fa-check"></i><b>2.1</b> Basic regression and statistical inference: Common mistakes and issues briefly listed</a></li>
<li class="chapter" data-level="2.2" data-path="reg-follies.html"><a href="reg-follies.html#bad-control"><i class="fa fa-check"></i><b>2.2</b> Bad control</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="reg-follies.html"><a href="reg-follies.html#bad-control-colliders-1"><i class="fa fa-check"></i><b>2.2.1</b> “Bad control” (“colliders”)</a></li>
<li class="chapter" data-level="2.2.2" data-path="reg-follies.html"><a href="reg-follies.html#choices-of-lhs-and-rhs-variables-1"><i class="fa fa-check"></i><b>2.2.2</b> Choices of lhs and rhs variables</a></li>
<li class="chapter" data-level="2.2.3" data-path="reg-follies.html"><a href="reg-follies.html#functional-form-1"><i class="fa fa-check"></i><b>2.2.3</b> Functional form</a></li>
<li class="chapter" data-level="2.2.4" data-path="reg-follies.html"><a href="reg-follies.html#ols-and-heterogeneity-1"><i class="fa fa-check"></i><b>2.2.4</b> OLS and heterogeneity</a></li>
<li class="chapter" data-level="2.2.5" data-path="reg-follies.html"><a href="reg-follies.html#null-effects-1"><i class="fa fa-check"></i><b>2.2.5</b> “Null effects”</a></li>
<li class="chapter" data-level="2.2.6" data-path="reg-follies.html"><a href="reg-follies.html#multiple-hypothesis-testing-mht-1"><i class="fa fa-check"></i><b>2.2.6</b> Multiple hypothesis testing (MHT)</a></li>
<li class="chapter" data-level="2.2.7" data-path="reg-follies.html"><a href="reg-follies.html#interaction-terms-and-pitfalls-1"><i class="fa fa-check"></i><b>2.2.7</b> Interaction terms and pitfalls</a></li>
<li class="chapter" data-level="2.2.8" data-path="reg-follies.html"><a href="reg-follies.html#choice-of-test-statistics-including-nonparametric-1"><i class="fa fa-check"></i><b>2.2.8</b> Choice of test statistics (including nonparametric)</a></li>
<li class="chapter" data-level="2.2.9" data-path="reg-follies.html"><a href="reg-follies.html#how-to-display-and-write-about-regression-results-and-tests-1"><i class="fa fa-check"></i><b>2.2.9</b> How to display and write about regression results and tests</a></li>
<li class="chapter" data-level="2.2.10" data-path="reg-follies.html"><a href="reg-follies.html#bayesian-interpretations-of-results-1"><i class="fa fa-check"></i><b>2.2.10</b> Bayesian interpretations of results</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="robust-diag.html"><a href="robust-diag.html"><i class="fa fa-check"></i><b>3</b> Robustness and diagnostics, with integrity</a>
<ul>
<li class="chapter" data-level="3.1" data-path="robust-diag.html"><a href="robust-diag.html#how-can-diagnostic-tests-make-sense-where-is-the-burden-of-proof-1"><i class="fa fa-check"></i><b>3.1</b> (How) can diagnostic tests make sense? Where is the burden of proof?</a></li>
<li class="chapter" data-level="3.2" data-path="robust-diag.html"><a href="robust-diag.html#estimating-standard-errors-1"><i class="fa fa-check"></i><b>3.2</b> Estimating standard errors</a></li>
<li class="chapter" data-level="3.3" data-path="robust-diag.html"><a href="robust-diag.html#sensitivity-analysis-interactive-presentation-1"><i class="fa fa-check"></i><b>3.3</b> Sensitivity analysis: Interactive presentation</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="control-ml.html"><a href="control-ml.html"><i class="fa fa-check"></i><b>4</b> Control strategies and prediction, Machine Learning (Statistical Learning) approaches</a>
<ul>
<li class="chapter" data-level="4.1" data-path="control-ml.html"><a href="control-ml.html#machine-learning-statistical-learning-lasso-ridge-and-more-1"><i class="fa fa-check"></i><b>4.1</b> Machine Learning (statistical learning): Lasso, Ridge, and more</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="control-ml.html"><a href="control-ml.html#limitations-to-inference-from-learning-approaches-1"><i class="fa fa-check"></i><b>4.1.1</b> Limitations to inference from learning approaches</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="control-ml.html"><a href="control-ml.html#notes-hastie-statistical-learning-with-sparsity"><i class="fa fa-check"></i><b>4.2</b> Notes Hastie: Statistical Learning with Sparsity</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="control-ml.html"><a href="control-ml.html#introduction-1"><i class="fa fa-check"></i><b>4.2.1</b> Introduction</a></li>
<li class="chapter" data-level="4.2.2" data-path="control-ml.html"><a href="control-ml.html#ch2-lasso-for-linear-models"><i class="fa fa-check"></i><b>4.2.2</b> Ch2: Lasso for linear models</a></li>
<li class="chapter" data-level="4.2.3" data-path="control-ml.html"><a href="control-ml.html#chapter-3-generalized-linear-models"><i class="fa fa-check"></i><b>4.2.3</b> Chapter 3: Generalized linear models</a></li>
<li class="chapter" data-level="4.2.4" data-path="control-ml.html"><a href="control-ml.html#chapter-4-generalizations-of-the-lasso-penalty"><i class="fa fa-check"></i><b>4.2.4</b> Chapter 4: Generalizations of the Lasso penalty</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="control-ml.html"><a href="control-ml.html#notes-mullainathan"><i class="fa fa-check"></i><b>4.3</b> Notes: Mullainathan</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="iv-and-its-many-issues-1.html"><a href="iv-and-its-many-issues-1.html"><i class="fa fa-check"></i><b>5</b> IV and its many issues</a>
<ul>
<li class="chapter" data-level="5.1" data-path="iv-and-its-many-issues-1.html"><a href="iv-and-its-many-issues-1.html#instrument-validity-1"><i class="fa fa-check"></i><b>5.1</b> Instrument validity</a></li>
<li class="chapter" data-level="5.2" data-path="iv-and-its-many-issues-1.html"><a href="iv-and-its-many-issues-1.html#heterogeneity-and-late-1"><i class="fa fa-check"></i><b>5.2</b> Heterogeneity and LATE</a></li>
<li class="chapter" data-level="5.3" data-path="iv-and-its-many-issues-1.html"><a href="iv-and-its-many-issues-1.html#weak-instruments-other-issues-1"><i class="fa fa-check"></i><b>5.3</b> Weak instruments, other issues</a></li>
<li class="chapter" data-level="5.4" data-path="iv-and-its-many-issues-1.html"><a href="iv-and-its-many-issues-1.html#reference-to-the-use-of-iv-in-experimentsmediation-1"><i class="fa fa-check"></i><b>5.4</b> Reference to the use of IV in experiments/mediation</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="causal-pathways-mediation-modeling-and-its-massive-limitations-1.html"><a href="causal-pathways-mediation-modeling-and-its-massive-limitations-1.html"><i class="fa fa-check"></i><b>6</b> Causal pathways: <span>Mediation modeling and its massive limitations</span></a>
<ul>
<li class="chapter" data-level="6.1" data-path="causal-pathways-mediation-modeling-and-its-massive-limitations-1.html"><a href="causal-pathways-mediation-modeling-and-its-massive-limitations-1.html#mediators-and-selection-and-roy-models-a-review-considering-two-research-applications"><i class="fa fa-check"></i><b>6.1</b> Mediators (and selection and Roy models): a review, considering two research applications</a></li>
<li class="chapter" data-level="6.2" data-path="causal-pathways-mediation-modeling-and-its-massive-limitations-1.html"><a href="causal-pathways-mediation-modeling-and-its-massive-limitations-1.html#dr-initial-thoughts-for-nl-education-paper"><i class="fa fa-check"></i><b>6.2</b> DR initial thoughts (for NL education paper)</a></li>
<li class="chapter" data-level="6.3" data-path="causal-pathways-mediation-modeling-and-its-massive-limitations-1.html"><a href="causal-pathways-mediation-modeling-and-its-massive-limitations-1.html#econometric-mediation-analyses-heckman-and-pinto"><i class="fa fa-check"></i><b>6.3</b> Econometric Mediation Analyses (Heckman and Pinto)</a>
<ul>
<li class="chapter" data-level="" data-path="causal-pathways-mediation-modeling-and-its-massive-limitations-1.html"><a href="causal-pathways-mediation-modeling-and-its-massive-limitations-1.html#relevance-to-parey-et-al"><i class="fa fa-check"></i>Relevance to Parey et al</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="causal-pathways-mediation-modeling-and-its-massive-limitations-1.html"><a href="causal-pathways-mediation-modeling-and-its-massive-limitations-1.html#summary-and-key-modeling"><i class="fa fa-check"></i><b>6.4</b> Summary and key modeling</a></li>
<li class="chapter" data-level="6.5" data-path="causal-pathways-mediation-modeling-and-its-massive-limitations-1.html"><a href="causal-pathways-mediation-modeling-and-its-massive-limitations-1.html#pinto-2015-selection-bias-in-a-controlled-experiment-the-case-of-moving-to-opportunity"><i class="fa fa-check"></i><b>6.5</b> Pinto (2015), Selection Bias in a Controlled Experiment: The Case of Moving to Opportunity</a></li>
<li class="chapter" data-level="" data-path="causal-pathways-mediation-modeling-and-its-massive-limitations-1.html"><a href="causal-pathways-mediation-modeling-and-its-massive-limitations-1.html#summary"><i class="fa fa-check"></i>Summary</a></li>
<li class="chapter" data-level="" data-path="causal-pathways-mediation-modeling-and-its-massive-limitations-1.html"><a href="causal-pathways-mediation-modeling-and-its-massive-limitations-1.html#relevance-to-parey-et-al-1"><i class="fa fa-check"></i>Relevance to Parey et al</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#introduction"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="" data-path="causal-pathways-mediation-modeling-and-its-massive-limitations-1.html"><a href="causal-pathways-mediation-modeling-and-its-massive-limitations-1.html#identification-strategy-brief"><i class="fa fa-check"></i>Identification strategy brief</a></li>
<li class="chapter" data-level="" data-path="causal-pathways-mediation-modeling-and-its-massive-limitations-1.html"><a href="causal-pathways-mediation-modeling-and-its-massive-limitations-1.html#results-in-brief"><i class="fa fa-check"></i>Results in brief</a></li>
<li class="chapter" data-level="" data-path="causal-pathways-mediation-modeling-and-its-massive-limitations-1.html"><a href="causal-pathways-mediation-modeling-and-its-massive-limitations-1.html#framework-first-for-binarybinary-simplification"><i class="fa fa-check"></i>Framework: first for binary/binary (simplification)</a></li>
<li class="chapter" data-level="" data-path="causal-pathways-mediation-modeling-and-its-massive-limitations-1.html"><a href="causal-pathways-mediation-modeling-and-its-massive-limitations-1.html#framework-for-mto-multiple-treatment-groups-multiple-choices"><i class="fa fa-check"></i>Framework for MTO multiple treatment groups, multiple choices</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="causal-pathways-selection-corners-hurdles-and-conditional-on-estimates-1.html"><a href="causal-pathways-selection-corners-hurdles-and-conditional-on-estimates-1.html"><i class="fa fa-check"></i><b>7</b> Causal pathways: selection, corners, hurdles, and ‘conditional on’ estimates</a>
<ul>
<li class="chapter" data-level="7.1" data-path="causal-pathways-selection-corners-hurdles-and-conditional-on-estimates-1.html"><a href="causal-pathways-selection-corners-hurdles-and-conditional-on-estimates-1.html#corner-solution-or-hurdle-variables-and-conditional-on-positive-1"><i class="fa fa-check"></i><b>7.1</b> ‘Corner solution’ or hurdle variables and ‘Conditional on Positive’</a></li>
<li class="chapter" data-level="7.2" data-path="causal-pathways-selection-corners-hurdles-and-conditional-on-estimates-1.html"><a href="causal-pathways-selection-corners-hurdles-and-conditional-on-estimates-1.html#bounding-approaches-lee-manski-etc-1"><i class="fa fa-check"></i><b>7.2</b> Bounding approaches (Lee, Manski, etc)</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="causal-pathways-selection-corners-hurdles-and-conditional-on-estimates-1.html"><a href="causal-pathways-selection-corners-hurdles-and-conditional-on-estimates-1.html#notes-training-wages-and-sample-selection-estimating-sharp-bounds-on-treatment-effects-david-lee-2009-restud"><i class="fa fa-check"></i><b>7.2.1</b> Notes: Training, Wages, and Sample Selection: Estimating Sharp Bounds on Treatment Effects, David Lee, 2009, RESTUD</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="notes-on-bayesian-approaches-david-reinstein.html"><a href="notes-on-bayesian-approaches-david-reinstein.html"><i class="fa fa-check"></i><b>8</b> Notes on Bayesian approaches – David Reinstein</a>
<ul>
<li class="chapter" data-level="8.1" data-path="notes-on-bayesian-approaches-david-reinstein.html"><a href="notes-on-bayesian-approaches-david-reinstein.html#my-uses-for-bayesian-approaches-brainstorm"><i class="fa fa-check"></i><b>8.1</b> My uses for Bayesian approaches (brainstorm)</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="notes-on-bayesian-approaches-david-reinstein.html"><a href="notes-on-bayesian-approaches-david-reinstein.html#meta-analysis-of-previous-evidence"><i class="fa fa-check"></i><b>8.1.1</b> Meta-analysis of previous evidence</a></li>
<li class="chapter" data-level="8.1.2" data-path="notes-on-bayesian-approaches-david-reinstein.html"><a href="notes-on-bayesian-approaches-david-reinstein.html#inference-particularly-about-null-effects"><i class="fa fa-check"></i><b>8.1.2</b> Inference, particularly about ‘null effects’</a></li>
<li class="chapter" data-level="8.1.3" data-path="notes-on-bayesian-approaches-david-reinstein.html"><a href="notes-on-bayesian-approaches-david-reinstein.html#policy-and-business-implications-and-recommendations"><i class="fa fa-check"></i><b>8.1.3</b> ‘Policy’ and business implications and recommendations</a></li>
<li class="chapter" data-level="8.1.4" data-path="notes-on-bayesian-approaches-david-reinstein.html"><a href="notes-on-bayesian-approaches-david-reinstein.html#theory-driven-inference-about-optimizing-agents-esp.-in-strategic-settings"><i class="fa fa-check"></i><b>8.1.4</b> Theory-driven inference about optimizing agents, esp. in strategic settings</a></li>
<li class="chapter" data-level="8.1.5" data-path="notes-on-bayesian-approaches-david-reinstein.html"><a href="notes-on-bayesian-approaches-david-reinstein.html#experimental-design"><i class="fa fa-check"></i><b>8.1.5</b> Experimental design</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="notes-on-bayesian-approaches-david-reinstein.html"><a href="notes-on-bayesian-approaches-david-reinstein.html#title-introduction-to-bayesian-analysis-in-r-and-stata---katz-qstep"><i class="fa fa-check"></i><b>8.2</b> Title: “Introduction to Bayesian analysis in R and Stata - Katz, Qstep”</a></li>
<li class="chapter" data-level="8.3" data-path="notes-on-bayesian-approaches-david-reinstein.html"><a href="notes-on-bayesian-approaches-david-reinstein.html#why-and-when-use-bayesian-mcmc-methods"><i class="fa fa-check"></i><b>8.3</b> Why and when use Bayesian (MCMC) methods?</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="notes-on-bayesian-approaches-david-reinstein.html"><a href="notes-on-bayesian-approaches-david-reinstein.html#pros"><i class="fa fa-check"></i><b>8.3.1</b> Pros</a></li>
<li class="chapter" data-level="8.3.2" data-path="notes-on-bayesian-approaches-david-reinstein.html"><a href="notes-on-bayesian-approaches-david-reinstein.html#cons"><i class="fa fa-check"></i><b>8.3.2</b> Cons</a></li>
<li class="chapter" data-level="8.3.3" data-path="notes-on-bayesian-approaches-david-reinstein.html"><a href="notes-on-bayesian-approaches-david-reinstein.html#why-more-popular-today"><i class="fa fa-check"></i><b>8.3.3</b> Why more popular today?</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="notes-on-bayesian-approaches-david-reinstein.html"><a href="notes-on-bayesian-approaches-david-reinstein.html#theory"><i class="fa fa-check"></i><b>8.4</b> Theory</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="notes-on-bayesian-approaches-david-reinstein.html"><a href="notes-on-bayesian-approaches-david-reinstein.html#so-how-do-we-estimate-it"><i class="fa fa-check"></i><b>8.4.1</b> So how do we estimate it?</a></li>
<li class="chapter" data-level="8.4.2" data-path="notes-on-bayesian-approaches-david-reinstein.html"><a href="notes-on-bayesian-approaches-david-reinstein.html#linear-regression-model-example"><i class="fa fa-check"></i><b>8.4.2</b> Linear regression model example</a></li>
<li class="chapter" data-level="8.4.3" data-path="notes-on-bayesian-approaches-david-reinstein.html"><a href="notes-on-bayesian-approaches-david-reinstein.html#gibbs"><i class="fa fa-check"></i><b>8.4.3</b> Gibbs</a></li>
<li class="chapter" data-level="8.4.4" data-path="notes-on-bayesian-approaches-david-reinstein.html"><a href="notes-on-bayesian-approaches-david-reinstein.html#metropolis-hastings"><i class="fa fa-check"></i><b>8.4.4</b> Metropolis Hastings</a></li>
<li class="chapter" data-level="8.4.5" data-path="notes-on-bayesian-approaches-david-reinstein.html"><a href="notes-on-bayesian-approaches-david-reinstein.html#assessing-convergence"><i class="fa fa-check"></i><b>8.4.5</b> Assessing convergence</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="notes-on-bayesian-approaches-david-reinstein.html"><a href="notes-on-bayesian-approaches-david-reinstein.html#comparing-models-equivalent-of-likelihood"><i class="fa fa-check"></i><b>8.5</b> Comparing models … Equivalent of ‘likelihood’</a></li>
<li class="chapter" data-level="8.6" data-path="notes-on-bayesian-approaches-david-reinstein.html"><a href="notes-on-bayesian-approaches-david-reinstein.html#on-choosing-priors"><i class="fa fa-check"></i><b>8.6</b> On choosing priors</a></li>
<li class="chapter" data-level="8.7" data-path="notes-on-bayesian-approaches-david-reinstein.html"><a href="notes-on-bayesian-approaches-david-reinstein.html#implementation"><i class="fa fa-check"></i><b>8.7</b> Implementation</a></li>
<li class="chapter" data-level="8.8" data-path="notes-on-bayesian-approaches-david-reinstein.html"><a href="notes-on-bayesian-approaches-david-reinstein.html#generate-predictions-from-a-winbugs-model"><i class="fa fa-check"></i><b>8.8</b> Generate predictions from a WinBUGS model</a></li>
<li class="chapter" data-level="8.9" data-path="notes-on-bayesian-approaches-david-reinstein.html"><a href="notes-on-bayesian-approaches-david-reinstein.html#missing-data-case"><i class="fa fa-check"></i><b>8.9</b> Missing data case</a></li>
<li class="chapter" data-level="8.10" data-path="notes-on-bayesian-approaches-david-reinstein.html"><a href="notes-on-bayesian-approaches-david-reinstein.html#stata"><i class="fa fa-check"></i><b>8.10</b> Stata</a></li>
<li class="chapter" data-level="8.11" data-path="notes-on-bayesian-approaches-david-reinstein.html"><a href="notes-on-bayesian-approaches-david-reinstein.html#r-mcmc-pac"><i class="fa fa-check"></i><b>8.11</b> R mcmc pac</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="_blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Econometrics, statistics, and data science: Reinstein notes with a Micro, Behaviural, and Experimental focus</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="notes-on-bayesian-approaches-david-reinstein" class="section level1" number="8">
<h1><span class="header-section-number">8</span> Notes on Bayesian approaches – David Reinstein</h1>
<div id="my-uses-for-bayesian-approaches-brainstorm" class="section level2" number="8.1">
<h2><span class="header-section-number">8.1</span> My uses for Bayesian approaches (brainstorm)</h2>
<div id="meta-analysis-of-previous-evidence" class="section level3" number="8.1.1">
<h3><span class="header-section-number">8.1.1</span> Meta-analysis of previous evidence</h3>
<ul>
<li><p>Of prior work, especially on motivators of (effective) charitable giving and responses to effectiveness information</p></li>
<li><p>Of my own series’ of experiments (potentially joint with prior work)</p></li>
</ul>
</div>
<div id="inference-particularly-about-null-effects" class="section level3" number="8.1.2">
<h3><span class="header-section-number">8.1.2</span> Inference, particularly about ‘null effects’</h3>
<p>When/what can we say about the ‘absence of an effect’</p>
<p>How to integrate into inferences from diagnostic testing (e.g., common-trend assumption)?</p>
</div>
<div id="policy-and-business-implications-and-recommendations" class="section level3" number="8.1.3">
<h3><span class="header-section-number">8.1.3</span> ‘Policy’ and business implications and recommendations</h3>
<ul>
<li>E.g., for ‘which pages to seed’</li>
</ul>
</div>
<div id="theory-driven-inference-about-optimizing-agents-esp.-in-strategic-settings" class="section level3" number="8.1.4">
<h3><span class="header-section-number">8.1.4</span> Theory-driven inference about optimizing agents, esp. in strategic settings</h3>
<ul>
<li>Especially in ‘predicted contributions to public goods’ settings and 2nd order beliefs</li>
</ul>
</div>
<div id="experimental-design" class="section level3" number="8.1.5">
<h3><span class="header-section-number">8.1.5</span> Experimental design</h3>
<ul>
<li><p>Optimal treatment assignment, with previous observables and a track record</p></li>
<li><p>Sequential designs</p></li>
</ul>
<p>( Bayesian Power calculation<br />
</p>
</div>
</div>
<div id="title-introduction-to-bayesian-analysis-in-r-and-stata---katz-qstep" class="section level2" number="8.2">
<h2><span class="header-section-number">8.2</span> Title: “Introduction to Bayesian analysis in R and Stata - Katz, Qstep”</h2>
</div>
<div id="why-and-when-use-bayesian-mcmc-methods" class="section level2" number="8.3">
<h2><span class="header-section-number">8.3</span> Why and when use Bayesian (MCMC) methods?</h2>
<div id="pros" class="section level3" number="8.3.1">
<h3><span class="header-section-number">8.3.1</span> Pros</h3>
<ol style="list-style-type: decimal">
<li><p>No need for asymptotics … good when sample sizes are small</p></li>
<li><p>Incorporate previous information</p></li>
</ol>
<p>You can consider the ‘robustness to other priors’</p>
<ol start="3" style="list-style-type: decimal">
<li><p>Fit complex nonstandard models
… e.g., with difficult functional forms or likelihood settings (more computation, less thinking)</p></li>
<li><p>Easy to make predictions (e.g., simulate scenarios) after estimation</p></li>
<li><p>Incorporate evidence, results, expert judgement</p></li>
</ol>
<p>(‘restrictions’ with some lee-way?)</p>
<p>(ISn’t this the same as number 2?)</p>
<ol start="6" style="list-style-type: decimal">
<li>Cleaner treatment/imputation of missing values … these are just parameters</li>
</ol>
</div>
<div id="cons" class="section level3" number="8.3.2">
<h3><span class="header-section-number">8.3.2</span> Cons</h3>
<ol style="list-style-type: decimal">
<li><p>Must specify prior distributions … allows subjective judgement</p></li>
<li><p>Different way of thinking about stats and inference; probability distributions and simulations, not much about p-values, point estimates and standard errors … path dependence</p></li>
<li><p>Computational cost</p></li>
</ol>
<p>This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <a href="http://rmarkdown.rstudio.com" class="uri">http://rmarkdown.rstudio.com</a>.</p>
<p>When you click the <strong>Knit</strong> button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:</p>
</div>
<div id="why-more-popular-today" class="section level3" number="8.3.3">
<h3><span class="header-section-number">8.3.3</span> Why more popular today?</h3>
<ul>
<li>Starting from around 2005 in Political Science and Sociology</li>
</ul>
<p>Computational revolution comes from Markov chain Monte Carlo (MCMC) methods … don’t need analytical solutions</p>
<p>Software implementations – many in R, specialised software like EWinBugs, JAGS, STAN; also increasingly in Stata</p>
</div>
</div>
<div id="theory" class="section level2" number="8.4">
<h2><span class="header-section-number">8.4</span> Theory</h2>
<p>Bayes theorem … inverting conditional probability thing … ‘inversion’ to make inferences about the parameters</p>
<ul>
<li>In Bayesian stats the <em>parameters</em> (and sometimes missing values) are random variables, we make probability statements about them</li>
</ul>
<p><span class="math display">\[P(A|B)=P(B|A)P(A)/P(B)\]</span></p>
<p>Frequentist: Point estimates, unknown fixed parameters, data from a hyol repeataable random sample</p>
<p>Bayesian: Fixed data (from the experiment), parameters are random variables … results based on probability distributions about rthese</p>
<p>Classical statistics: likelihood of data given parameter: <span class="math inline">\(p(y|\theta)\)</span></p>
<p>Bayes we want, <span class="math inline">\(p(\theta|y) = p(y|\theta)p(\theta)/p(y)\)</span></p>
<p><span class="math inline">\(p(y)\)</span> is a ‘constant’ in our estimation … the data is fixed.</p>
<p>So it’s proportional to <span class="math inline">\(p(\theta|y) = p(y|\theta)\times p(\theta)\)</span></p>
<p><span class="math inline">\(p(y|\theta)\)</span> is what we max when we do ML</p>
<p>$ p()$: prior distribution capturing beliefs about <span class="math inline">\(\theta\)</span></p>
<div id="so-how-do-we-estimate-it" class="section level3" number="8.4.1">
<h3><span class="header-section-number">8.4.1</span> So how do we estimate it?</h3>
<ol style="list-style-type: decimal">
<li><p>Specify a probability model, a distribution for Y (likelihood function) and the priors for <span class="math inline">\(\theta\)</span></p></li>
<li><p>Solve (find) the posterior distribution <span class="math inline">\(p(\theta|Y)\)</span> and summarise the parameters of interest</p></li>
</ol>
<p>In practice, step 2 is usually done via MCMC simulation rather than analytically.</p>
<p>… via simulations, I approach the ‘true’ value on <span class="math inline">\(\theta\)</span></p>
<p>(Given ‘regularity conditions’)</p>
</div>
<div id="linear-regression-model-example" class="section level3" number="8.4.2">
<h3><span class="header-section-number">8.4.2</span> Linear regression model example</h3>
<p><span class="math display">\[Y = x&#39;\beta+\epsilon\]</span> with n obs</p>
<p>only random term is epsilon … natural candidate is a normal distribution, so <span class="math inline">\(Y \sim N(x&#39;\beta,\sigma^2_e)\)</span></p>
<p>So we want to find <span class="math inline">\(p(\beta, \sigma^2_\epsilon|Y,X)\)</span>. This depends on the choices of <span class="math inline">\(p(\beta)\)</span> and <span class="math inline">\(p(\epsilon)\)</span>. Could choose conjugate priors, leading to a particular joint posterior, you can solve it analytically.</p>
<p>Can yield a joint posterior.</p>
<p>Instead, let’s assume that the latter (variance) parameter is known, you can show that the posterior for <span class="math inline">\(\beta\)</span> is also normally distributed. (Conjugate)</p>
<p>Similarly, if we assume <span class="math inline">\(\beta\)</span> is known, if the variance term had an inverse gamma distribution (prior), so will the posterior.</p>
<p>In these conjugate priors, the posterior mean will be a weighted average of the priors and the data.</p>
</div>
<div id="gibbs" class="section level3" number="8.4.3">
<h3><span class="header-section-number">8.4.3</span> Gibbs</h3>
<p>Needs closed form conditional posterior for every parameter.</p>
<p>What Gibbs sampler does is break the parameter space into sets of parameters</p>
<ol style="list-style-type: decimal">
<li><p>Choose starting values, <span class="math inline">\(\theta^0_1,...\theta^0_k\)</span></p></li>
<li><p>sample from the first parameter’s distribution given the others
… the second one, … the k’th one .</p></li>
<li><p>Repeat step 2 … thousands of times (starting with the parameters from the previous iteration)
Eventually ‘we obtain samples of <span class="math inline">\(p(\theta|y)\)</span>’</p></li>
</ol>
<p><em>But if we don’t have a closed form, we cannot simply sample from known distributions in each step</em></p>
<p>E.g., in case of Logit distribution.</p>
</div>
<div id="metropolis-hastings" class="section level3" number="8.4.4">
<h3><span class="header-section-number">8.4.4</span> Metropolis Hastings</h3>
<ol style="list-style-type: decimal">
<li>Choose ‘proposal distribution’ to sample parameter values (a candidate like normal, uniform)</li>
<li>Start w a prelim guess for parameter values <span class="math inline">\(\theta_0\)</span></li>
<li>At iteration t sample a proposal <span class="math inline">\(\theta_t\)</span> from <span class="math inline">\(p(\theta_t|\theta_{t-1})\)</span> ?? what does this come from?</li>
<li>If <span class="math inline">\(p(\theta_t|y)&gt;p(\theta_{t-1}|y)\)</span> accept it as the new value of <span class="math inline">\(\theta\)</span>. ??? how is this computed if we don’t have conjugate closed-form posteriors?</li>
<li>Otherwise flip a coin with probability r = (ratio of those probabilities)</li>
</ol>
<ul>
<li>if coin tosses heads, accept as new theta, otherwise stay at previous theta</li>
<li>allows algorithm to avoid getting stuck at local maxima</li>
</ul>
<p>Commonly used proposal: random walk sample: <span class="math inline">\(\theta_t=\theta_{t-1}+z_t\)</span>, <span class="math inline">\(z_t \sim f\)</span></p>
<p>?? I do this because there is no analytical way to derive this, unlike in the conjugate case, where we might use the Gibbs</p>
<ul>
<li>can combine Gibbs with Metropolis steps; relevant to some problems</li>
</ul>
</div>
<div id="assessing-convergence" class="section level3" number="8.4.5">
<h3><span class="header-section-number">8.4.5</span> Assessing convergence</h3>
<ul>
<li>previous … ‘eyeballing’</li>
<li>formal:
<ul>
<li>single-chain tests (Geweke/Heidel) … is the last part of the chain stable (stationary)… compare simulation at middle and end, is there much variation?</li>
<li>multiple-chain test… (starting from different values), do they end similar … Gelman-Rubin diagnosting <span class="math inline">\(\hat{R}\)</span></li>
<li>typically either a very long chain and use GH convergence, or multiple shorter chains and use <span class="math inline">\(\hat{R}\)</span></li>
</ul></li>
</ul>
<p>Gabriel: Gelman-Rubin is probably preferred; more conservative</p>
<p>?? What am I iterating towards? Converging on what?</p>
<p>###Assesing ‘fit’ in Bayesian</p>
<ul>
<li>No r-squared</li>
<li>Typical measure is ‘posterior predictive comparisons’</li>
</ul>
<p><span class="math inline">\(p(y_{replicated}|y_{observed}= ...\)</span></p>
<ol style="list-style-type: decimal">
<li>Simulate data from estimated parameters</li>
<li>Compare to observed data</li>
<li>Use an overall fit measure to assess model fit</li>
</ol>
<p>E.g., percent correct predictions (binary), whether the true data is within the 95% CI of the replicates, deviance</p>
<p>For each replicate Choose statistic D, compare the replicated <span class="math inline">\(D(y_s_{replicated})\)</span> against $D(y_s_{observed})</p>
<p>Quantify the discrepancy … percent of correct predictions, proportion of times replicated y is below true y … compute ‘bayesian p-value’s’</p>
<p>Systematic differences between replicate and actual data indicate model limitations</p>
<p>(?? what are reasonable values here??)</p>
</div>
</div>
<div id="comparing-models-equivalent-of-likelihood" class="section level2" number="8.5">
<h2><span class="header-section-number">8.5</span> Comparing models … Equivalent of ‘likelihood’</h2>
<p>‘Deviance Information Criterion’ (most used); specific for MCMC simulations: compares expected LL of the model (of the data given the estimated parameters; average here across much of the later points in the chain) against the llhd at the posterior parameter mean. Always select model with lowest DIC.</p>
<p>Bayes Factor (less used): Ratio of llhd of the models; higher BF means model is more supported; BF&gt;10 seen to provide strong evidence for model w higher value</p>
</div>
<div id="on-choosing-priors" class="section level2" number="8.6">
<h2><span class="header-section-number">8.6</span> On choosing priors</h2>
<p>Most social scientists use non-informative or vague priors; i.e., large variance… e.g., <span class="math inline">\(\beta \sim N(0,1000)\)</span></p>
<p>But its often useful to incorporate information into your priors</p>
<p>Small pilot to test, <span class="math inline">\(\rightarrow\)</span> data <span class="math inline">\(Y_1\)</span>, another study gives data <span class="math inline">\(Y_2\)</span>; repeated application of Bayes theorem gives the posterior.</p>
<p>Same result whether you obtained these together, or whether you did one and then updated (e.g., via an MCMC, starting with the first one as a prior)</p>
<p>Conjugate priors (mentioned before)</p>
<ul>
<li>Jeffrey’s priors (??)</li>
</ul>
</div>
<div id="implementation" class="section level2" number="8.7">
<h2><span class="header-section-number">8.7</span> Implementation</h2>
<p>If you don’t need to do fancy things, and don’t want to (?) generate the full posterior distribution (or something)</p>
<p>Some Stata/R commands that make Bayesian look frequentist.</p>
<p>In Jags and Winbugs, we only have to specify the prior… rest is done for us</p>
<p>Jags is great … you only need to do self-coding with lots of data and super complicated models as it can freeze up</p>
<p>We went through it the fancy way in Probit.R</p>
<p>Then the easy way with ‘script probit Jags.R’</p>
</div>
<div id="generate-predictions-from-a-winbugs-model" class="section level2" number="8.8">
<h2><span class="header-section-number">8.8</span> Generate predictions from a WinBUGS model</h2>
<p>You can just generate these outcomes …</p>
<p>Prediction: generate a new observation #note, he is doing one per iteration, but since these are convergent it would be basically the same if you just chose a random iteration and did all the draws from that one</p>
</div>
<div id="missing-data-case" class="section level2" number="8.9">
<h2><span class="header-section-number">8.9</span> Missing data case</h2>
<p>One solution – multiple imputation</p>
<ul>
<li>choose imputation model to predict missings,</li>
<li>generate many copies of orig data set, imputing missibg value for each</li>
<li>2 more steps here</li>
</ul>
<p>Need a model for X|alpha, because missing variables are random variables</p>
</div>
<div id="stata" class="section level2" number="8.10">
<h2><span class="header-section-number">8.10</span> Stata</h2>
<p>Has some rather simple implementations; e.g., just using commands like ```bayes: regress y x ’’’</p>
</div>
<div id="r-mcmc-pac" class="section level2" number="8.11">
<h2><span class="header-section-number">8.11</span> R mcmc pac</h2>
<p>Also simple code; great for standard use</p>
<p>Speedup with parallelization; see “script for parallel probit.R” and “parallelprobit.R”</p>
<p>More advanced: C++; can integrate it with Rcpp, or even use Exeter’s ISCA cluster</p>
<p>``{r cars}
summary(cars)
```</p>

<div id="refs" class="references hanging-indent">
<div>
<p>Angrist J. D., and J S Pischke. 2008. “Mostly Harmless Econometrics : An Empiricist ’ S Companion.” <em>Massachusettts I Nstitute of Technology and the London School of Economics</em>, no. March: 290. <a href="https://doi.org/10.1017/CBO9781107415324.004">https://doi.org/10.1017/CBO9781107415324.004</a>.</p>
</div>
<div>
<p>Gentzkow, Matthew. 2013. “Code and Data for the Social Sciences : A Practitioner ’ S Guide.”</p>
</div>
<div>
<p>Heckman, James, Rodrigo Pinto, and James Heckman. 2013. “Econometric Mediation Analyses : Identifying the Sources of Treatment Effects from Experimentally Estimated Production Technologies with Unmeasured and Mismeasured Inputs,” no. 7552.</p>
</div>
<div>
<p>Kennedy, Peter. 2003. <em>A Guide to Econometrics</em>. MIT press.</p>
</div>
<div>
<p>Tibshirani, Robert. n.d. “Statistical Learning with Sparsity the Lasso and Generalizations.”</p>
</div>
<div>
<p>Wooldridge, Jeffrey M. 2002. <em>Econometric Analysis of Cross Section and Panel Data</em>. 2. The MIT press. <a href="https://doi.org/10.1515/humr.2003.021">https://doi.org/10.1515/humr.2003.021</a>.</p>
</div>
<div>
<p>Wooldridge, J M. 2008. <em>Introductory Econometrics: A Modern Approach</em>. South-Western Pub.</p>
</div>
</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Cf ‘winning institution’ impacts human capital, social networks,
etc identically for everyone; e.g., not a greater effect for men
then for women, nor a greater effect for those entering particular
specializations.<a href="causal-pathways-mediation-modeling-and-its-massive-limitations-1.html#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>Cf ‘winning institution’ does not effect the specialization
entered nor the location of residence, nor are both determined by a
third factor.<a href="causal-pathways-mediation-modeling-and-its-massive-limitations-1.html#fnref2" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="causal-pathways-selection-corners-hurdles-and-conditional-on-estimates-1.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": true,
"weibo": true,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"],
"google": false
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
