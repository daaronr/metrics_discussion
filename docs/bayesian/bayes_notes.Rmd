# Notes on Bayesian approaches -- David Reinstein

## My uses for Bayesian approaches (brainstorm)

### Meta-analysis of previous evidence

- Of prior work, especially on motivators of (effective) charitable giving and responses to effectiveness information

- Of my own series' of experiments (potentially joint with prior work)

### Inference, particularly about 'null effects'

When/what can we say about the 'absence of an effect'

How to integrate into inferences from diagnostic testing (e.g., common-trend assumption)?

### 'Policy' and business implications and recommendations

- E.g., for 'which pages to seed'

### Theory-driven inference about optimizing agents, esp. in strategic settings

- Especially in 'predicted contributions to public goods' settings and 2nd order beliefs

### Experimental design

- Optimal treatment assignment, with previous observables and a track record

- Sequential designs

( Bayesian Power calculation
\


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Title: "Introduction to Bayesian analysis in R and Stata - Katz, Qstep"

*Content from notes from this lecture*

### Why and when use Bayesian (MCMC) methods?

#### Pros
1. No need for asymptotics ... good when sample sizes are small

2. Incorporate previous information

You can consider the 'robustness to other priors'

3. Fit complex nonstandard models
... e.g., with difficult functional forms or likelihood settings (more computation, less thinking)

4. Easy to make predictions (e.g., simulate scenarios) after estimation

5. Incorporate evidence, results, expert judgement

('restrictions' with some lee-way?)

(ISn't this the same as number 2?)

6. Cleaner treatment/imputation of missing values ... these are just parameters

#### Cons

1. Must specify prior distributions ... allows subjective judgement

2. Different way of thinking about stats and inference; probability distributions and simulations, not much about p-values, point estimates and standard errors ... path dependence

3. Computational cost

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:


#### Why more popular today?

- Starting from around 2005 in Political Science and Sociology

Computational revolution comes from Markov chain Monte Carlo (MCMC) methods ... don't need analytical solutions

Software implementations -- many in R, specialised software like EWinBugs, JAGS, STAN; also increasingly in Stata


### Theory

Bayes theorem ... inverting conditional probability thing ... 'inversion' to make inferences about the parameters

- In Bayesian stats the *parameters* (and sometimes missing values) are random variables, we make probability statements about them

$$P(A|B)=P(B|A)P(A)/P(B)$$


Frequentist: Point estimates, unknown fixed parameters, data from a hyol repeataable random sample

Bayesian: Fixed data (from the experiment), parameters are random variables ... results based on probability distributions about rthese

Classical statistics: likelihood of data given parameter: $p(y|\theta)$

Bayes we want, $p(\theta|y) = p(y|\theta)p(\theta)/p(y)$

$p(y)$  is a 'constant' in our estimation ... the data is fixed.

So it's proportional to $p(\theta|y) = p(y|\theta)\times p(\theta)$

$p(y|\theta)$ is what we max when we do ML

$ p(\theta)$: prior distribution capturing beliefs about $\theta$

#### So how do we estimate it?

1.  Specify a probability model, a distribution for Y (likelihood function) and the priors for $\theta$

2. Solve (find) the posterior distribution $p(\theta|Y)$ and summarise the parameters of interest

In practice, step 2 is usually done via MCMC simulation rather than analytically.

... via simulations, I approach the 'true' value on $\theta$

(Given 'regularity conditions')

#### Linear regression model example

$$Y = x'\beta+\epsilon$$ with n obs

only random term is epsilon ... natural candidate is a normal distribution, so $Y \sim N(x'\beta,\sigma^2_e)$


So we want to find $p(\beta, \sigma^2_\epsilon|Y,X)$. This depends on the choices of $p(\beta)$ and $p(\epsilon)$. Could choose conjugate priors, leading to a particular joint posterior, you can solve it analytically.

Can yield a joint posterior.

Instead, let's assume that the latter (variance) parameter is known, you can show that the posterior for $\beta$ is also normally distributed. (Conjugate)

Similarly, if we assume $\beta$ is known, if the variance term had an inverse gamma distribution (prior), so will the posterior.

In these conjugate priors, the posterior mean will be a weighted average of the priors and the data.

#### Gibbs

Needs closed form conditional posterior for every parameter.

What Gibbs sampler does is break the parameter space into sets of parameters

1. Choose starting values, $\theta^0_1,...\theta^0_k$

2. sample from the first parameter's distribution given the others
... the second one, ... the k'th one .

3. Repeat step 2 ... thousands of times (starting with the parameters from the previous iteration)
Eventually 'we obtain samples of $p(\theta|y)$'

*But if we don't have a closed form, we cannot simply sample from known distributions in each step*

E.g., in case of Logit distribution.

#### Metropolis Hastings

1. Choose 'proposal distribution' to sample parameter values (a candidate like normal, uniform)
1. Start w a prelim guess for parameter values $\theta_0$
1. At iteration t sample a proposal $\theta_t$  from $p(\theta_t|\theta_{t-1})$ ?? what does this come from?
1. If $p(\theta_t|y)>p(\theta_{t-1}|y)$ accept it as the new value of $\theta$. ??? how is this computed if we don't have conjugate closed-form posteriors?
1. Otherwise flip a coin  with probability  r = (ratio of those probabilities)
- if coin tosses heads, accept as new theta, otherwise stay at previous theta
-  allows algorithm to avoid getting stuck at local maxima

Commonly used proposal: random walk sample: $\theta_t=\theta_{t-1}+z_t$, $z_t \sim f$

?? I do this because there is no analytical way to derive this, unlike in the conjugate case, where we might use the Gibbs

- can combine Gibbs with Metropolis steps; relevant to some problems

#### Assessing convergence

- previous ... 'eyeballing'
- formal:
  - single-chain tests (Geweke/Heidel) ... is the last part of the chain stable (stationary)... compare simulation at middle and end, is there much variation?
  - multiple-chain test... (starting from different values), do they end similar ... Gelman-Rubin diagnosting $\hat{R}$
  - typically either a very long chain and use GH convergence, or multiple shorter chains and use $\hat{R}$

Gabriel: Gelman-Rubin is probably preferred; more conservative

?? What am I iterating towards? Converging on what?

#### Assesing 'fit' in Bayesian

- No r-squared
- Typical measure is 'posterior predictive comparisons'

$p(y_{replicated}|y_{observed}= ...$

1. Simulate data from estimated parameters
2. Compare to observed data
3. Use an overall fit measure to assess model fit

E.g.,   percent correct predictions (binary), whether the true data is within the 95\% CI of the replicates, deviance

For each replicate Choose statistic D, compare the replicated $D(y_s_{replicated})$ against $D(y_s_{observed})

Quantify the discrepancy ... percent of correct predictions, proportion of times replicated y is below true y ... compute 'bayesian p-value's'

Systematic differences between replicate and actual data indicate model limitations

(?? what are reasonable values here??)

### Comparing models ... Equivalent of 'likelihood'

'Deviance Information Criterion' (most used); specific for MCMC simulations: compares expected LL of the model (of the data given the estimated parameters; average here across much of the later points in the chain) against the llhd at the posterior parameter mean.   Always select model with lowest DIC.

Bayes Factor (less used): Ratio of llhd of the models; higher BF means model is more supported; BF>10 seen to provide strong evidence for model w higher value

### On choosing priors

Most social scientists use non-informative or vague priors; i.e., large variance... e.g., $\beta \sim N(0,1000)$

But its often useful to incorporate information into your priors

Small pilot to test, $\rightarrow$ data $Y_1$, another study gives data $Y_2$; repeated application of Bayes theorem gives the posterior.

Same result whether you obtained these together, or whether you did one and then updated (e.g., via an MCMC, starting with the first one as a prior)

Conjugate priors (mentioned before)

- Jeffrey's priors (??)

### Implementation

If you don't need to do fancy things, and don't want to (?) generate the full posterior distribution (or something)

Some Stata/R commands that make Bayesian look frequentist.

In Jags and Winbugs, we only have to specify the prior... rest is done for us

Jags is great ... you only need to do self-coding with lots of data and super complicated models as it can freeze up

We went through it the fancy way in Probit.R

Then the easy way with 'script probit Jags.R'

### Generate predictions from a WinBUGS model

You can just generate these outcomes ...

Prediction: generate a new observation #note, he is doing one per iteration, but since these are convergent it would be basically the same if you just chose a random iteration and did all the draws from that one

### Missing data case

One solution -- multiple imputation

- choose imputation model to predict missings,
- generate many copies of orig data set, imputing missibg value for each
- 2 more steps here

Need a model for X|alpha, because missing variables are random variables

### Stata

Has some rather simple implementations; e.g., just using commands like ```bayes: regress y x```

### R mcmc pac

Also simple code; great for standard use

Speedup with parallelization; see "script for parallel probit.R" and "parallelprobit.R"

More advanced: C++; can integrate it with Rcpp, or even use Exeter's ISCA cluster


```{r cars}
summary(cars)
```

